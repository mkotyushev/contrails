seed_everything: 0
trainer:
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      project: contrails
  callbacks:
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    # - class_path: src.utils.utils.EarlyStoppingNotReached
    #   init_args:
    #     monitor: v_dice
    #     mode: max
    #     patience: 10
    #     critical_value: 0.3
    #     critical_epoch: 7

  # limit_train_batches: 10
  # limit_val_batches: 10
  max_epochs: 64
  num_sanity_val_steps: 0
  accumulate_grad_batches: 4
  reload_dataloaders_every_n_epochs: 0
  log_every_n_steps: 1
  gradient_clip_val: 5
  check_val_every_n_epoch: 1
  precision: 16-mixed

  gradient_clip_algorithm: norm
  deterministic: true
  benchmark: false
  enable_checkpointing: true

  fast_dev_run: false
  profiler: null
  detect_anomaly: false
  
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  enable_progress_bar: null
  enable_model_summary: null
  inference_mode: true
  use_distributed_sampler: true
  barebones: false
  plugins: null
  sync_batchnorm: false
  default_root_dir: null
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
model:
  class_path: src.model.modules.SegmentationModule
  init_args:
    in_channels: 3
    library: smp
    architecture: unet
    backbone_name: null
    log_preview_every_n_epochs: 1
    tta_params: null
    tta_single_index: null
    # tta_params: 
    #   aggr: mean
    #   n_random_replays: 0
    #   use_hflip: false
    #   use_vflip: false
    #   # rotate90_indices: [1, 2, 3]
    #   # shift_params:
    #   # - [0, 2]
    #   # - [2, 0]
    #   # - [2, 2]
    #   # scale_factors: [0.875, 1.125]  # 256 +- 32
    #   # scale_factors: [0.9375, 1.0625]  # 512 +- 32
    #   # scale_factors: [0.96875, 1.03125]  # 1024 +- 32
    #   # for scale [1, 2], ~ x20 slower than 256, 256 * [...]
    #   # scale_factors: [1.125, 1.25, 1.5, 1.625, 1.75, 1.875, 2.0]
    #   # for scale [1, 2], 320 * [...] = 348, 448, 512
    #   # scale_factors: [1.2, 1.4, 1.6]
    #   # for scale [1, 2], 256 * [...] = [288, 320, 352, 384, 416, 448, 480, 512]
    #   # scale_factors: [1.125, 1.25, 1.375, 1.5, 1.625, 1.75, 1.875, 2.0]
    #   # for scale [1, 4], ~ x50 slower than 256, 256 * [...]
    #   # scale_factors: [1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
    pretrained: imagenet
    mechanize: false
    loss_name: bce=0.9+dice=0.1
    pos_weight: 0.035
    label_smoothing: 0.0
    optimizer_init: 
      class_path: torch.optim.AdamW
      init_args:
        weight_decay: 1e-6
        lr: 1e-4
        eps: 1e-08
    # optimizer_init: 
    #   class_path: bitsandbytes.optim.AdamW8bit
    #   init_args:
    #     weight_decay: 1e-6
    #     lr: 1e-4
    #     eps: 1e-08
    # optimizer_init: 
    #   class_path: bitsandbytes.optim.Lion8bit
    #   init_args:
    #     weight_decay: 1e-6
    #     lr: 1e-4
    lr_scheduler_init:
      class_path: src.utils.lr_scheduler.PiecewiceFactorsLRScheduler
      init_args:
        milestones: [0, 0.1, 1.0]
        pieces:
          - class_path: src.utils.lr_scheduler.LinearLRSchedulerPiece
            init_args:
              start_lr: 1e-1
              stop_lr: 1
          - class_path: src.utils.lr_scheduler.CosineLRSchedulerPiece
            init_args:
              start_lr: 1
              stop_lr: 1e-2
    pl_lrs_cfg:
      interval: step
      frequency: 1
    finetuning: null
    lr_layer_decay: 1.0
    verbose: 0
    n_bootstrap: 0
    fill_metric_nan: null
    prog_bar_names: 
      - dice
    grad_checkpointing: false
    compile: true
    lr: null  # needed for sweeps
    postprocess: null
    pretrained_ckpt_path: null
    add_dice_thresholded: false
    add_dataloader_idx: false
data:
  class_path: src.data.datamodules.ContrailsDatamodule
  init_args:
    data_dirs: 
      - ../data/train
      - ../data/validation
    data_dirs_test: null
    num_folds: 5
    fold_index: 0
    fold_index_outer: null
    test_as_aux_val: false
    img_size: 256
    img_size_val_test: null  # same as img_size
    random_state: 0
    sampler_type: null
    randaugment_num_ops: 3
    randaugment_magnitude: 9
    scale_factor: null
    crop_uniform: null
    cat_mode: null
    num_frames: null  # only for not_labeled_mode == "video"
    dataset_kwargs:
      band_ids: [11, 14, 15]
      mask_type: voting50
      not_labeled_mode: null
      pseudolabels_path: null
      conversion_type: ash
      quantize: true
      stats_precomputed: false
    remove_pseudolabels_from_val_test: true
    mmap: true
    disable_cache: false
    cache_dir: cache
    to_predict: test
    split_info_path: ./split_info.csv
    empty_mask_strategy: null
    mix_transform_name: null
    batch_size: 32
    batch_size_val_test: null  # same as batch_size
    num_workers: 8
    pin_memory: true
    prefetch_factor: 1
    persistent_workers: true
